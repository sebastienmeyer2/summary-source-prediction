{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7747c1a1",
   "metadata": {},
   "source": [
    "# Summary source prediction: Embedded models\n",
    "\n",
    "Sébastien Meyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51387363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.utils import tokenize, effective_n_jobs\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    BatchNormalization, Bidirectional, Conv1D, Flatten, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D\n",
    ")\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import transformers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from src.preprocessing.features.embeddings import text_to_tokens, text_to_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681762bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "punct = string.punctuation.replace(\"-\", \"\")\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b81314c",
   "metadata": {},
   "source": [
    "## Dictionary and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5907360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"data/train_set.json\")\n",
    "test_df = pd.read_json(\"data/test_set.json\")\n",
    "documents = pd.read_json(\"data/documents.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e919935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:11<00:00, 677.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [01:17<00:00, 643.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All documents clean.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning documents...\")\n",
    "\n",
    "train_df[\"document_token\"] = train_df[\"document\"].progress_apply(\n",
    "    lambda x: text_to_tokens(x, stopwords, punct, remove_stopwords=True)\n",
    ")\n",
    "\n",
    "documents[\"document_token\"] = documents[\"document\"].progress_apply(\n",
    "    lambda x: text_to_tokens(x, stopwords, punct, remove_stopwords=True)\n",
    ")\n",
    "\n",
    "print(\"All documents clean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473f90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = train_df[\"document_token\"].to_list() + documents[\"document_token\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032cb866",
   "metadata": {},
   "source": [
    "## Choose your embeddings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c20c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [01:39, 22074.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196007 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pretrained GloVe embeddings\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(\"data/embed/glove_300.txt\", encoding=\"utf8\")\n",
    "\n",
    "for line in tqdm(f):\n",
    "    \n",
    "    values = line.strip().split(\" \")\n",
    "    try:\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "    except ValueError:\n",
    "        print(values[0])\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64c9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Google Word2Vec embeddings\n",
    "# embeddings_index = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "#     \"data/embed/google_300.gz\", binary=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be833e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your own Word2Vec embeddings\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"Callback to print loss after each epoch.\"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        \n",
    "        total_loss = model.get_latest_training_loss()\n",
    "        current_loss = total_loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = total_loss\n",
    "        \n",
    "        print(f\"Loss after epoch {self.epoch}: {current_loss}\")\n",
    "        \n",
    "        self.epoch += 1\n",
    "\n",
    "# w2v = word2vec.Word2Vec(\n",
    "#     all_docs, vector_size=300, window=20, min_count=5, workers=effective_n_jobs(-1), epochs=25,\n",
    "#     compute_loss=True, callbacks=[callback()]\n",
    "# )\n",
    "\n",
    "# embeddings_index = w2v.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d8f77",
   "metadata": {},
   "source": [
    "## Train test split and transf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ba58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = df_train[\"summary\"].to_numpy()\n",
    "y_train = df_train[\"label\"].to_numpy().flatten()\n",
    "x_val = df_val[\"summary\"].to_numpy()\n",
    "y_val = df_val[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ee913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6400/6400 [00:01<00:00, 5869.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:00<00:00, 6375.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "x_train_glove = [text_to_vec(embeddings_index, x, stopwords, punct, remove_stopwords=True) for x in tqdm(x_train)]\n",
    "x_val_glove = [text_to_vec(embeddings_index, x, stopwords, punct, remove_stopwords=True) for x in tqdm(x_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9252ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_glove = np.array(x_train_glove)\n",
    "x_val_glove = np.array(x_val_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3e1ab",
   "metadata": {},
   "source": [
    "## Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eda9923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.558125\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(x_train_glove, y_train)\n",
    "\n",
    "y_pred = logreg.predict(x_val_glove)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a5e7b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56125\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    max_depth=7, n_estimators=200, colsample_bytree=0.8, subsample=0.8, nthread=10, \n",
    "    learning_rate=0.1, use_label_encoder=False, eval_metric=\"logloss\", random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(x_train_glove, y_train)\n",
    "\n",
    "y_pred = xgb.predict(x_val_glove)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654cb6",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ca7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data before any neural net\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train_glove_scl = sc.fit_transform(x_train_glove)\n",
    "x_val_glove_scl = sc.transform(x_val_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c988e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to binarize the labels for the neural net\n",
    "y_train_hot = np_utils.to_categorical(y_train)\n",
    "y_val_hot = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca43d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd22caf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 2s 4ms/step - loss: 0.9017 - accuracy: 0.5089 - val_loss: 0.7190 - val_accuracy: 0.5375\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.5795 - val_loss: 0.7116 - val_accuracy: 0.5256\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6105 - val_loss: 0.7120 - val_accuracy: 0.5444\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6339 - val_loss: 0.7229 - val_accuracy: 0.5462\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6648 - val_loss: 0.7298 - val_accuracy: 0.5362\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6742 - val_loss: 0.7471 - val_accuracy: 0.5425\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7122 - val_loss: 0.7633 - val_accuracy: 0.5425\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7264 - val_loss: 0.7865 - val_accuracy: 0.5519\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7434 - val_loss: 0.8076 - val_accuracy: 0.5331\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7595 - val_loss: 0.8334 - val_accuracy: 0.5462\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7848 - val_loss: 0.8849 - val_accuracy: 0.5562\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7964 - val_loss: 0.8845 - val_accuracy: 0.5631\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8166 - val_loss: 0.9431 - val_accuracy: 0.5456\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8270 - val_loss: 0.9551 - val_accuracy: 0.5456\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8375 - val_loss: 0.9926 - val_accuracy: 0.5500\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8473 - val_loss: 1.0190 - val_accuracy: 0.5362\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8658 - val_loss: 1.0475 - val_accuracy: 0.5619\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8709 - val_loss: 1.0676 - val_accuracy: 0.5481\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8861 - val_loss: 1.1244 - val_accuracy: 0.5431\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8802 - val_loss: 1.1594 - val_accuracy: 0.5437\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8942 - val_loss: 1.1846 - val_accuracy: 0.5331\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9027 - val_loss: 1.2491 - val_accuracy: 0.5362\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9097 - val_loss: 1.2269 - val_accuracy: 0.5425\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9156 - val_loss: 1.3164 - val_accuracy: 0.5288\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9125 - val_loss: 1.3140 - val_accuracy: 0.5544\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9183 - val_loss: 1.2983 - val_accuracy: 0.5406\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9272 - val_loss: 1.3944 - val_accuracy: 0.5469\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9230 - val_loss: 1.3658 - val_accuracy: 0.5456\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.9298 - val_loss: 1.4313 - val_accuracy: 0.5400\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9314 - val_loss: 1.4442 - val_accuracy: 0.5275\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.1752 - accuracy: 0.9314 - val_loss: 1.4698 - val_accuracy: 0.5425\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9320 - val_loss: 1.4566 - val_accuracy: 0.5419\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9403 - val_loss: 1.4738 - val_accuracy: 0.5406\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9475 - val_loss: 1.5267 - val_accuracy: 0.5319\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9505 - val_loss: 1.5622 - val_accuracy: 0.5500\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9453 - val_loss: 1.6283 - val_accuracy: 0.5263\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9466 - val_loss: 1.5915 - val_accuracy: 0.5288\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9464 - val_loss: 1.5644 - val_accuracy: 0.5425\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9430 - val_loss: 1.5756 - val_accuracy: 0.5375\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9400 - val_loss: 1.5647 - val_accuracy: 0.5300\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9513 - val_loss: 1.5934 - val_accuracy: 0.5312\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9502 - val_loss: 1.6734 - val_accuracy: 0.5356\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9528 - val_loss: 1.6033 - val_accuracy: 0.5294\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9589 - val_loss: 1.6923 - val_accuracy: 0.5419\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9528 - val_loss: 1.7301 - val_accuracy: 0.5238\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9586 - val_loss: 1.6930 - val_accuracy: 0.5312\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9614 - val_loss: 1.7068 - val_accuracy: 0.5431\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9556 - val_loss: 1.7307 - val_accuracy: 0.5337\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9609 - val_loss: 1.7711 - val_accuracy: 0.5487\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9525 - val_loss: 1.7149 - val_accuracy: 0.5462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffac3e57cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_glove_scl, y=y_train_hot, batch_size=64, \n",
    "    epochs=50, verbose=1, \n",
    "    validation_data=(x_val_glove_scl, y_val_hot)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469036fd",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35e757c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(x_train) + list(x_val))\n",
    "x_train_seq = token.texts_to_sequences(x_train)\n",
    "x_val_seq = token.texts_to_sequences(x_val)\n",
    "\n",
    "# Zero pad the sequences\n",
    "x_train_pad = sequence.pad_sequences(x_train_seq, maxlen=max_len)\n",
    "x_val_pad = sequence.pad_sequences(x_val_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c261739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28873/28873 [00:00<00:00, 242742.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "\n",
    "    if word in embeddings_index:\n",
    "        embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        np.random.normal(size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f16448b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 13:34:19.440553: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34648800 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# A simple LSTM and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "518981f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 5s 224ms/step - loss: 0.7042 - accuracy: 0.5128 - val_loss: 0.6889 - val_accuracy: 0.5350\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.6986 - accuracy: 0.5192 - val_loss: 0.6806 - val_accuracy: 0.5663\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.6902 - accuracy: 0.5450 - val_loss: 0.6740 - val_accuracy: 0.5888\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6810 - accuracy: 0.5730 - val_loss: 0.6650 - val_accuracy: 0.5931\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 3s 204ms/step - loss: 0.6638 - accuracy: 0.6023 - val_loss: 0.6435 - val_accuracy: 0.6331\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 0.6570 - accuracy: 0.6184 - val_loss: 0.6626 - val_accuracy: 0.5994\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 3s 225ms/step - loss: 0.6418 - accuracy: 0.6363 - val_loss: 0.6339 - val_accuracy: 0.6388\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 3s 210ms/step - loss: 0.6363 - accuracy: 0.6408 - val_loss: 0.6614 - val_accuracy: 0.6050\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.6421 - accuracy: 0.6339 - val_loss: 0.6578 - val_accuracy: 0.6137\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 0.6327 - accuracy: 0.6517 - val_loss: 0.6301 - val_accuracy: 0.6444\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.6245 - accuracy: 0.6542 - val_loss: 0.6327 - val_accuracy: 0.6450\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.6142 - accuracy: 0.6733 - val_loss: 0.6225 - val_accuracy: 0.6538\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.6056 - accuracy: 0.6753 - val_loss: 0.6299 - val_accuracy: 0.6550\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 3s 212ms/step - loss: 0.6098 - accuracy: 0.6745 - val_loss: 0.6425 - val_accuracy: 0.6494\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 0.6045 - accuracy: 0.6770 - val_loss: 0.6280 - val_accuracy: 0.6587\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 3s 213ms/step - loss: 0.5949 - accuracy: 0.6839 - val_loss: 0.6221 - val_accuracy: 0.6606\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.5910 - accuracy: 0.6905 - val_loss: 0.6172 - val_accuracy: 0.6712\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.5782 - accuracy: 0.6947 - val_loss: 0.6365 - val_accuracy: 0.6594\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 3s 218ms/step - loss: 0.5779 - accuracy: 0.7020 - val_loss: 0.6632 - val_accuracy: 0.6513\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 0.5786 - accuracy: 0.7002 - val_loss: 0.6400 - val_accuracy: 0.6562\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 3s 210ms/step - loss: 0.5608 - accuracy: 0.7103 - val_loss: 0.6308 - val_accuracy: 0.6650\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 3s 212ms/step - loss: 0.5566 - accuracy: 0.7148 - val_loss: 0.6730 - val_accuracy: 0.6394\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.5522 - accuracy: 0.7222 - val_loss: 0.7606 - val_accuracy: 0.6231\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 0.5506 - accuracy: 0.7248 - val_loss: 0.6459 - val_accuracy: 0.6569\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 0.5452 - accuracy: 0.7322 - val_loss: 0.6601 - val_accuracy: 0.6575\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 3s 218ms/step - loss: 0.5357 - accuracy: 0.7289 - val_loss: 0.6807 - val_accuracy: 0.6469\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 0.5273 - accuracy: 0.7395 - val_loss: 0.6625 - val_accuracy: 0.6712\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.5097 - accuracy: 0.7517 - val_loss: 0.6757 - val_accuracy: 0.6619\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 0.5049 - accuracy: 0.7502 - val_loss: 0.6814 - val_accuracy: 0.6600\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.4899 - accuracy: 0.7620 - val_loss: 0.7565 - val_accuracy: 0.6331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff90ff9bf50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_pad, y=y_train_hot, batch_size=512,\n",
    "    epochs=30, verbose=1, \n",
    "    validation_data=(x_val_pad, y_val_hot)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687bc358",
   "metadata": {},
   "source": [
    "## Bidirectional LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d22f2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 13:35:46.519582: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34648800 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# A simple bidirectional LSTM and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=0, mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ab57d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 10s 420ms/step - loss: 0.7157 - accuracy: 0.4975 - val_loss: 0.6915 - val_accuracy: 0.5031\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 0.7015 - accuracy: 0.5080 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 7s 498ms/step - loss: 0.6959 - accuracy: 0.5138 - val_loss: 0.6913 - val_accuracy: 0.5200\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 5s 411ms/step - loss: 0.6958 - accuracy: 0.5033 - val_loss: 0.6908 - val_accuracy: 0.5562\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 5s 395ms/step - loss: 0.6944 - accuracy: 0.5058 - val_loss: 0.6909 - val_accuracy: 0.5581\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 0.6887 - accuracy: 0.5295 - val_loss: 0.6888 - val_accuracy: 0.5625\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 5s 413ms/step - loss: 0.6892 - accuracy: 0.5298 - val_loss: 0.6864 - val_accuracy: 0.5638\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 0.6876 - accuracy: 0.5383 - val_loss: 0.6828 - val_accuracy: 0.5906\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 6s 486ms/step - loss: 0.6855 - accuracy: 0.5320 - val_loss: 0.6800 - val_accuracy: 0.6200\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 6s 495ms/step - loss: 0.6763 - accuracy: 0.5584 - val_loss: 0.6715 - val_accuracy: 0.6206\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 0.6745 - accuracy: 0.5717 - val_loss: 0.6633 - val_accuracy: 0.6200\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 6s 430ms/step - loss: 0.6689 - accuracy: 0.5822 - val_loss: 0.6550 - val_accuracy: 0.6206\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 5s 402ms/step - loss: 0.6625 - accuracy: 0.5994 - val_loss: 0.6517 - val_accuracy: 0.6438\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 5s 402ms/step - loss: 0.6547 - accuracy: 0.6137 - val_loss: 0.6399 - val_accuracy: 0.6519\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 5s 395ms/step - loss: 0.6505 - accuracy: 0.6209 - val_loss: 0.6315 - val_accuracy: 0.6531\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 5s 405ms/step - loss: 0.6360 - accuracy: 0.6430 - val_loss: 0.6234 - val_accuracy: 0.6619\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 6s 432ms/step - loss: 0.6417 - accuracy: 0.6356 - val_loss: 0.6279 - val_accuracy: 0.6650\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 6s 430ms/step - loss: 0.6259 - accuracy: 0.6566 - val_loss: 0.6208 - val_accuracy: 0.6581\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 6s 434ms/step - loss: 0.6201 - accuracy: 0.6670 - val_loss: 0.6138 - val_accuracy: 0.6825\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 5s 407ms/step - loss: 0.6111 - accuracy: 0.6742 - val_loss: 0.6113 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.5972 - accuracy: 0.6934 - val_loss: 0.6407 - val_accuracy: 0.6169\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 0.6022 - accuracy: 0.6866 - val_loss: 0.6032 - val_accuracy: 0.6756\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.5988 - accuracy: 0.6923 - val_loss: 0.6232 - val_accuracy: 0.6550\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 6s 440ms/step - loss: 0.5874 - accuracy: 0.6938 - val_loss: 0.6283 - val_accuracy: 0.6456\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 5s 417ms/step - loss: 0.5841 - accuracy: 0.7070 - val_loss: 0.6001 - val_accuracy: 0.6906\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 6s 437ms/step - loss: 0.5730 - accuracy: 0.7102 - val_loss: 0.6212 - val_accuracy: 0.6712\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 6s 409ms/step - loss: 0.5546 - accuracy: 0.7286 - val_loss: 0.6090 - val_accuracy: 0.6837\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 5s 416ms/step - loss: 0.5643 - accuracy: 0.7245 - val_loss: 0.5999 - val_accuracy: 0.6925\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.5527 - accuracy: 0.7256 - val_loss: 0.6042 - val_accuracy: 0.6862\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 0.5593 - accuracy: 0.7244 - val_loss: 0.6380 - val_accuracy: 0.6556\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 6s 429ms/step - loss: 0.5514 - accuracy: 0.7362 - val_loss: 0.6053 - val_accuracy: 0.6906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff87559b350>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_pad, y=y_train, batch_size=512, \n",
    "    epochs=100, verbose=1, \n",
    "    validation_data=(x_val_pad, y_val), callbacks=[earlystop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6097bfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 13:42:23.300596: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34648800 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# GRU and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=0, mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2de99c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 8s 374ms/step - loss: 0.7148 - accuracy: 0.4922 - val_loss: 0.6913 - val_accuracy: 0.5206\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 5s 365ms/step - loss: 0.7028 - accuracy: 0.5108 - val_loss: 0.6868 - val_accuracy: 0.5506\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 5s 409ms/step - loss: 0.6944 - accuracy: 0.5339 - val_loss: 0.6805 - val_accuracy: 0.5706\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 5s 353ms/step - loss: 0.6873 - accuracy: 0.5609 - val_loss: 0.6713 - val_accuracy: 0.5894\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 5s 360ms/step - loss: 0.6837 - accuracy: 0.5761 - val_loss: 0.6760 - val_accuracy: 0.5844\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 5s 382ms/step - loss: 0.6752 - accuracy: 0.5742 - val_loss: 0.6724 - val_accuracy: 0.5719\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 5s 407ms/step - loss: 0.6732 - accuracy: 0.5863 - val_loss: 0.6589 - val_accuracy: 0.6388\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 5s 372ms/step - loss: 0.6664 - accuracy: 0.5945 - val_loss: 0.6428 - val_accuracy: 0.6338\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 5s 419ms/step - loss: 0.6574 - accuracy: 0.6161 - val_loss: 0.6356 - val_accuracy: 0.6456\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 0.6424 - accuracy: 0.6336 - val_loss: 0.6297 - val_accuracy: 0.6519\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 0.6490 - accuracy: 0.6322 - val_loss: 0.6375 - val_accuracy: 0.6250\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 5s 406ms/step - loss: 0.6399 - accuracy: 0.6416 - val_loss: 0.6399 - val_accuracy: 0.6350\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 5s 375ms/step - loss: 0.6317 - accuracy: 0.6469 - val_loss: 0.6341 - val_accuracy: 0.6594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff87470de50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_pad, y=y_train, \n",
    "    batch_size=512, epochs=100, \n",
    "    verbose=1, validation_data=(x_val_pad, y_val), callbacks=[earlystop]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itmnlp",
   "language": "python",
   "name": "itmnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
